# -*- coding: utf-8 -*-
"""NN Punching shear .ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1EZzRwZCug_aEC7P5mpOQ237tH2j3HeLy
"""

from sklearn import preprocessing
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd
from sklearn.preprocessing import MinMaxScaler , StandardScaler , MaxAbsScaler , Normalizer
from sklearn.model_selection import train_test_split
from sklearn.metrics import r2_score

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Activation
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input, Dense

from google.colab import files
uploaded = files.upload()

# !gdown id--1-16kYWkXZxmtWoHAeIZT3bmfKuP65YGm
# https://drive.google.com/file/d/1-16kYWkXZxmtWoHAeIZT3bmfKuP65YGm/view?usp=share_link

result=[]
neu1=[16,32,64]
neu2=[16,32,64]
Batch=[64 ,128,256]
optimizer=['adam' , 'SGD','RMSprop']
active=['relu' , 'linear' ]  
for i in neu1:
  for j in neu2:
    for t in Batch:
      for m in optimizer:
        for n in active:
          df = pd.read_excel('/content/New ex.xlsx'  ,header = 0 )
          y = df.loc[:, 'Pmax (kN)'].to_numpy().reshape((-1, 1))
          X = df.iloc[:, [0,1,2,3,4,5]].to_numpy()
          Xtr , Xte , ytr , yte = train_test_split(X,y, train_size = 0.8 ,random_state=42 ) 
          scalerX=MinMaxScaler()
          Xtr1=scalerX.fit_transform(Xtr)
          Xte1=scalerX.transform(Xte)
          scalery=MinMaxScaler()
          ytr1=scalery.fit_transform(ytr)
          yte1=scalery.transform(yte)

          input_layer = Input(shape=(6,), name='input_layer')
          Layer_1 = Dense(i, activation=n, name='Layer_1')(input_layer)
          Layer_2 = Dense(j, activation=n, name='Layer_2')(Layer_1)
          y1_output = Dense(1, activation="linear", name='y1_output')(Layer_2)
          model = Model(inputs=input_layer, outputs= y1_output)
          model.compile(optimizer=m, loss='mse')
          history = model.fit(Xtr1,ytr1, epochs=800, verbose=False,
                    batch_size=t, validation_data=(Xte1,yte1))
          predictions_te = model.predict(Xte1)
          predictions_tr = model.predict(Xtr1)
          c=r2_score(ytr1 , predictions_tr)
          d=r2_score(yte1 , predictions_te)
          result.append((i,j,t,m,n,c,d))
result.sort(key=lambda x:x[6])
print(result[-1])

model.summary()

predictions = model.predict(Xte1)
predicted_PunchingShear = predictions
plt.scatter(yte, predicted_PunchingShear)
plt.xlabel('actual PunchingShear')
plt.ylabel('predicted PunchingShear')

trpred = model.predict(Xtr1)
tepred = model.predict(Xte1)

r2tr = r2_score(ytr1 , trpred)
r2te = r2_score(yte1 , tepred)
    
print(f'Train R2 Score: {round(r2tr, 6)}')
print(f'Test  R2 Score: {round(r2te, 6)}')

a = min([np.min(trpred), np.min(tepred), 0])
b = max([np.max(trpred), np.max(tepred), 1])

plt.scatter(ytr1, trpred, s=12, facecolors='none', edgecolors='orangered')
plt.plot([a, b], [a, b], c='black', lw=1.4, label='y = x')
plt.title(f'XGBoost Train [R2 = {round(lr_r2tr, 4)}]')
plt.xlabel('V test (kN)')
plt.ylabel('V Predicted (kN)')
plt.legend()
plt.show()

# plt.subplot(1, 2, 2)
plt.scatter(yte1, tepred, s=12, facecolors='none', edgecolors='orangered')
plt.plot([a, b], [a, b], c='black', lw=1.4, label='y = x')
plt.title(f'XGBoost Test [R2 = {round(lr_r2te, 4)}]')
plt.xlabel('V test (kN)')
plt.ylabel('V Predicted (kN)')
plt.legend()
plt.show()

    # plt.show()

plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.legend(['train_loss', 'val_loss'])

from prettytable import PrettyTable
# result=[]
# neu1=[16,32,64]
# neu2=[16,32,64]
# Batch=[64 ,128,256]
# optimizer=['adam' , 'SGD','RMSprop']
# active=['relu' , 'linear' ] 
myTable = PrettyTable(["Layer1", "Layer2" , 'batch size','optimizer','active funtion'])

# Add rows
myTable.add_row([neu1[0],neu2[0],Batch[0],optimizer[0],active[0]])
myTable.add_row([neu1[1],neu2[1],Batch[1],optimizer[1],active[1]])
myTable.add_row([neu1[2],neu2[2],Batch[2],optimizer[2],'_'])


print(myTable)

myTable = PrettyTable(['Rank','R2_test_score','R2_train_score',"Layer1 ", "Layer2 " , 'batch size','optimizer ','active funtion'])


myTable.add_row([1,result[-1][6],result[-1][5],result[-1][0],result[-1][1],result[-1][2],result[-1][3],result[-1][4]])
myTable.add_row([1,result[-2][6],result[-2][5],result[-2][0],result[-2][1],result[-2][2],result[-2][3],result[-2][4]])
myTable.add_row([1,result[-3][6],result[-3][5],result[-3][0],result[-3][1],result[-3][2],result[-3][3],result[-3][4]])
myTable.add_row([1,result[-4][6],result[-4][5],result[-4][0],result[-4][1],result[-4][2],result[-4][3],result[-4][4]])




print(myTable)